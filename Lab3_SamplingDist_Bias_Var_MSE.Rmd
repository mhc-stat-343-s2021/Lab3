---
title: "Lab 3: Sampling Distributions, Bias, Variance, and MSE"
subtitle: "STAT 343: Mathetmatical Statistics"
output:
  html_document
---

\newcommand{\simiid}{{\mathrel {\mathop {\sim}\limits _{}^{\rm iid}}\,}}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(ggplot2)
```

# Sampling distribution of variance estimates

Suppose that $X_1, \ldots, X_n \simiid \text{Normal}(\mu, \sigma^2)$.

Consider the following three estimators of $\sigma^2$:

${\hat{\sigma}^2}^{Unbiased} = \frac{1}{n-1} \sum_{i = 1}^n (X_i - \bar{X})^2$

${\hat{\sigma}^2}^{MLE} = \frac{1}{n} \sum_{i = 1}^n (X_i - \bar{X})^2$

${\hat{\sigma}^2}^{MinMSE} = \frac{1}{n+1} \sum_{i = 1}^n (X_i - \bar{X})^2$

We have found theoretically that (as reflected in their names), ${\hat{\sigma}^2}^{Unbiased}$ is an unbiased estimator of $\sigma^2$ and ${\hat{\sigma}^2}^{MinMSE}$ has the smallest MSE of these three estimators.

Let's conduct a simulation study to see this in action.  Bias, variance, and mean squared error are descriptions of the sampling distribution of estimators; they describe behavior of the estimators across many different realizations of the sample data.  To understand the relationships between bias, variance, and MSE from a simulation study, we need to simulate many different data sets and calculate all three estimators based on each of the simulated data sets.

The following code sets up a structure to do this.  We will simulate 10000 different data sets, where each data set consists of $n = 5$ observations drawn from a $Normal(5, 2^2)$ distribution.

#### 1. In the loop below, we enter the code to calculate the three estimates based on the simulated data vector x. Review this code, but there is no need to modify it.

```{r}
# set a seed for random number generation so the results are reproducible
set.seed(57336)
# sample size and the true mu and sigma used for simulating data
n <- 5
true_mu <- 5
true_sigma <- 2
# number of simulated data sets to generate
num_sims <- 10000
# Set up a data frame to store our estimates.
#
# Think of this as an empty spreadsheet with three columns:
# one each to store our three different estimates.
#
# There are 10000 rows, giving us space to store the parameter
# estimates from each simulated data set.
estimates <- data.frame(
  est_unbiased = rep(NA, num_sims),
  est_mle = rep(NA, num_sims),
  est_min_mse = rep(NA, num_sims)
)
# The for loop below runs once for each number in the result of calling seq_len(num_sims).
# seq_len(num_sims) generates a sequence of integers starting at 1 and going up to 10000
# Basically the code inside the curly braces will run 10000 times
# Each time the code runs, the variable i will have a different value between 1 and 10000
for(i in seq_len(num_sims)) {
  # simulate a data set of size n with specified mean and standard deviation
  # after this line, x is a vector of 5 numbers
  x <- rnorm(n, mean = true_mu, sd = true_sigma)
  
  # calculate the sample mean of the x's.  You will want to use this below.
  sample_mean <- mean(x)
  
  # calculate each of the three estimates based on the sample values in x.
  estimates$est_unbiased[i] <- sum((x - sample_mean)^2) / (n - 1)
  estimates$est_mle[i] <- sum((x - sample_mean)^2) / n
  estimates$est_min_mse[i] <- sum((x - sample_mean)^2) / (n + 1)
}
```

You may find it helpful to take a look at the estimates data frame by running the code below.  You should see that there are 10000 rows (you don't need to scroll all the way down) and three columns with the estimates from the three approaches.  You may notice that the estimate from the unbiased approach is always larger than the corresponding estimate from the approach with minimum MSE.

```{r}
View(estimates)
```

#### 2. Calculate an estimate of the bias, variance, and MSE for each of the three estimators. 



```{r}

```

```{r}

```

```{r}

```

#### 3. Below are plots of the estimates of these parameters across our 10000 simulated data sets, along with vertical lines showing the mean estimate for each approach.  What does this plot have to do with a sampling distribution?  How do the bias and variance of the estimators show up in the plot?

```{r fig.align='center'}
ggplot(data = estimates) +
  geom_vline(xintercept = true_sigma^2) +
  geom_density(mapping = aes(x = est_unbiased), color = "purple") +
  geom_density(mapping = aes(x = est_mle), color = "orange") +
  geom_density(mapping = aes(x = est_min_mse), color = "cornflowerblue") +
  geom_vline(xintercept = mean(estimates$est_unbiased), color = "purple") +
  geom_vline(xintercept = mean(estimates$est_mle), color = "orange") +
  geom_vline(xintercept = mean(estimates$est_min_mse), color = "cornflowerblue") + 
  theme_bw()
```

